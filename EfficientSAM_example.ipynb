{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xhhr4iSQuQq_"
      },
      "source": [
        "#Efficient SAM Example"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AIrAUKnLClPD"
      },
      "source": [
        "This script provides example for how to get visualization result from EfficientSAM using ready-to-use torchscript, part of the code is borrow from MobileSAM project, many thanks!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zylNfpYIuXeR"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I64YhiKsS2KU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "import io"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_4lyT8uMvy"
      },
      "source": [
        "#Box and Point prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hrhmpHroFUH"
      },
      "outputs": [],
      "source": [
        "def run_ours_box_or_points(img_path, pts_sampled, pts_labels, model):\n",
        "    image_np = np.array(Image.open(img_path))\n",
        "    img_tensor = ToTensor()(image_np)\n",
        "    pts_sampled = torch.reshape(torch.tensor(pts_sampled), [1, 1, -1, 2])\n",
        "    pts_labels = torch.reshape(torch.tensor(pts_labels), [1, 1, -1])\n",
        "    predicted_logits, predicted_iou = model(\n",
        "        img_tensor[None, ...],\n",
        "        pts_sampled,\n",
        "        pts_labels,\n",
        "    )\n",
        "\n",
        "    sorted_ids = torch.argsort(predicted_iou, dim=-1, descending=True)\n",
        "    predicted_iou = torch.take_along_dim(predicted_iou, sorted_ids, dim=2)\n",
        "    predicted_logits = torch.take_along_dim(\n",
        "        predicted_logits, sorted_ids[..., None, None], dim=2\n",
        "    )\n",
        "\n",
        "    return torch.ge(predicted_logits[0, 0, 0, :, :], 0).cpu().detach().numpy()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-83WUeNPuJnT"
      },
      "source": [
        "#Visualization Related"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKWt76-AG31h"
      },
      "outputs": [],
      "source": [
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.8])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels == 1]\n",
        "    neg_points = coords[labels == 0]\n",
        "    ax.scatter(\n",
        "        pos_points[:, 0],\n",
        "        pos_points[:, 1],\n",
        "        color=\"green\",\n",
        "        marker=\"*\",\n",
        "        s=marker_size,\n",
        "        edgecolor=\"white\",\n",
        "        linewidth=1.25,\n",
        "    )\n",
        "    ax.scatter(\n",
        "        neg_points[:, 0],\n",
        "        neg_points[:, 1],\n",
        "        color=\"red\",\n",
        "        marker=\"*\",\n",
        "        s=marker_size,\n",
        "        edgecolor=\"white\",\n",
        "        linewidth=1.25,\n",
        "    )\n",
        "\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(\n",
        "        plt.Rectangle((x0, y0), w, h, edgecolor=\"yellow\", facecolor=(0, 0, 0, 0), lw=5)\n",
        "    )\n",
        "\n",
        "\n",
        "def show_anns_ours(mask, ax):\n",
        "    ax.set_autoscale_on(False)\n",
        "    img = np.ones((mask.shape[0], mask.shape[1], 4))\n",
        "    img[:, :, 3] = 0\n",
        "    # for ann in mask:\n",
        "    #     m = ann\n",
        "    color_mask = np.concatenate([np.random.random(3), [0.5]])\n",
        "    img[mask] = color_mask\n",
        "    ax.imshow(img)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GHj10cGetlGN"
      },
      "source": [
        "#Create the model and load the weights from the checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HR4CCpYUpAI"
      },
      "outputs": [],
      "source": [
        "from efficient_sam import build_efficient_sam\n",
        "\n",
        "efficient_sam = build_efficient_sam('model_ckpt.pth')\n",
        "efficient_sam.eval()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b76-PTdKuidf"
      },
      "source": [
        "## Box segmentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ed2uLDCSDn"
      },
      "source": [
        "prepare your own image here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xq7KloryJrhf"
      },
      "outputs": [],
      "source": [
        "x1=400\n",
        "y1=200\n",
        "x2=800\n",
        "y2=600\n",
        "w=x2-x1\n",
        "h=y3-y1\n",
        "input_point = np.array([[x1, y1], [x2, y2]])\n",
        "input_label = np.array([2,3])\n",
        "image_path = \"figs/examples/dogs.jpg\"\n",
        "\n",
        "mask_ours = run_ours_box_or_points(image_path, input_point, input_label, efficient_sam)\n",
        "image = np.array(Image.open(image_path))\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "show_box([x1,y1,x2,y2], plt.gca())\n",
        "plt.imshow(image)\n",
        "show_anns_ours(mask_ours, plt.gca())\n",
        "plt.title(f\"EfficientSAM\", fontsize=18)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6IQBINppEQXW"
      },
      "source": [
        "## Point segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jpWTIwoNG452"
      },
      "outputs": [],
      "source": [
        "input_point = np.array([[580, 350], [650, 350]])\n",
        "input_label = np.array([1, 1])\n",
        "image_path = \"figs/examples/dogs.jpg\"\n",
        "mask_ours = run_ours_box_or_points(image_path, input_point, input_label, efficient_sam)\n",
        "image = np.array(Image.open(image_path))\n",
        "plt.figure(figsize=(20, 20))\n",
        "show_points(input_point, input_label, plt.gca())\n",
        "plt.imshow(image)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(image)\n",
        "show_anns_ours(mask_ours, plt.gca())\n",
        "plt.title(f\"EfficientSAM\", fontsize=18)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
